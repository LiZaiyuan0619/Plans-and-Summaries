# 11.21习得

## EasyScholar

温习了easyscholar插件的应用，还是蛮有用的：
只要登录状态，即可一键翻译所选文本，T键；可以显示文献分区；可以当作收藏器来用；显示图标可以连接到SCI-HUB

## Zotero

装上了connecter，在浏览器中可一键添加文献到zotero中

稍微了解和设置了一下zotero的基本功能

后面等待GPT4的插件[MuiseDestiny/zotero-gpt: GPT Meet Zotero. (github.com)](https://github.com/MuiseDestiny/zotero-gpt)

安装GPT插件同时试试下面这几个插件

[windingwind/zotero-better-notes: Everything about note management. All in Zotero. (github.com)](https://github.com/windingwind/zotero-better-notes)

[MuiseDestiny/zotero-style: Ethereal Style for Zotero (github.com)](https://github.com/MuiseDestiny/zotero-style)**+**[Zotero Style (notion.so)](https://www.notion.so/Zotero-Style-bc2aebbbb6df4b7baa858e376e4fc5be)

[ethanwillis/zotero-scihub: A plugin that will automatically download PDFs of zotero items from sci-hub (github.com)](https://github.com/ethanwillis/zotero-scihub)

[jlegewie/zotfile: Zotero plugin to manage your attachments: automatically rename, move, and attach PDFs (or other files) to Zotero items, sync PDFs from your Zotero library to your (mobile) PDF reader (e.g. an iPad, Android tablet, etc.), and extract PDF annotations. (github.com)](https://github.com/jlegewie/zotfile)

[wshanks/Zutilo: Zotero plugin providing some additional editing features (github.com)](https://github.com/wshanks/Zutilo)

# arxiv

注册了账号，了解了基本使用

下载了插件，不过感觉用处不大

## GPT使用技巧

temperature控制GPT的创造性

## 关于YOLO的调研

目前学术界用于剪枝的YOLO版本v5居多

2023.7在arxiv上出现了一篇关于YOLOv5模型压缩的综述，提及**“在众多版本的YOLO中，作者特别选择了YOLOv5，因为它在最新性和文献中的流行性之间取得了出色的平衡。”**下图是YOLO版本的历史迭代，YOLOv5一直到去年还在更新，也就是在去年v6,v7开始出现，今年出现了v8

![image-20231121143735659](C:\Users\李在渊\AppData\Roaming\Typora\typora-user-images\image-20231121143735659.png)

文章原文见[Model Compression Methods for YOLOv5: A Review | Abstract (arxiv.org)](https://arxiv.org/abs/2307.11904)

分析（翻译）见[YOLO落地部署 | 一文全览YOLOv5最新的剪枝、量化的进展【必读】-腾讯云开发者社区-腾讯云 (tencent.com)](https://cloud.tencent.com/developer/article/2322901)

### 摘抄：

标检测的主要目标是从给定图像中识别和定位不同类别的目标

通常，目标检测可以通过两种方法进行，即单阶段和两阶段检测。在前者中，算法直接预测目标的边界框和类别概率，而在后者中，算法首先生成一组区域建议，然后对这些建议进行目标或背景的分类。不同于两阶段目标检测方法，如Faster R-CNN和R-FCN，单阶段方法如YOLO、SSD、EfficientDet和RetinaNet通常使用一个完全卷积神经网络（FCN）来检测目标的类别和空间位置，而不需要中间步骤。

YOLO的主要思想是将输入图像分成一个单元格网格，并为每个单元格预测边界框和类别概率。YOLO将目标检测视为回归问题。

---

### 其他的YOLO信息

YOLOv5的网络结构分为四个部分：输入端、Backbone、Neck和输出端

- [输入端：YOLOv5的输入端主要是对输入图像进行预处理，包括缩放、裁剪、归一化等操作。YOLOv5的输入图像的尺寸可以是任意的，但是为了提高效率，一般采用32的倍数，例如640x640。YOLOv5的输入端没有采用mosaic数据增强，而是使用了其他的数据增强方法，例如MixUp、CutMix、RandomAffine等](https://zhuanlan.zhihu.com/p/172121380)[1](https://zhuanlan.zhihu.com/p/172121380)。
- [Backbone：YOLOv5的Backbone是用来提取图像的特征的部分，它采用了CSPNet](https://github.com/ultralytics/yolov5)[2](https://github.com/ultralytics/yolov5)[的结构，即Cross Stage Partial Network，这是一种将特征图分成两部分，一部分直接传递到下一层，另一部分经过卷积操作后再与前一部分相加的方式，可以减少计算量，提高特征的多样性。YOLOv5的Backbone有四种不同的版本，分别是YOLOv5s、YOLOv5m、YOLOv5l和YOLOv5x，它们的区别主要在于深度和宽度，即层数和通道数。YOLOv5s是最小的版本，YOLOv5x是最大的版本，YOLOv5m和YOLOv5l是中间的版本。YOLOv5的Backbone的输出是三个不同尺度的特征图，分别是C3、C4和C5，它们的尺寸分别是输入图像的1/8、1/16和1/32，通道数分别是256、512和1024。YOLOv5的Backbone的剪枝方法主要是基于权重的剪枝，即根据权重的绝对值或标准差，删除权重较小或较大的通道或卷积核，从而减少参数和计算量](https://cloud.tencent.com/developer/article/1997288)[3](https://cloud.tencent.com/developer/article/1997288)[4](https://zhuanlan.zhihu.com/p/424869462)[5](https://blog.csdn.net/qq_44878985/article/details/129287587)。
- [Neck：YOLOv5的Neck是用来融合不同尺度的特征的部分，它采用了FPN](https://youtu.be/LNwODJXcvt4)[6](https://youtu.be/LNwODJXcvt4)[和PAN](https://zhuanlan.zhihu.com/p/172121380)[7](https://docs.ultralytics.com/help/)[的结构，即Feature Pyramid Network和Path Aggregation Network，这是一种自顶向下和自底向上的双向特征融合的方式，可以增强特征的语义信息，提高检测的精度。YOLOv5的Neck的输出是三个不同尺度的特征图，分别是P3、P4和P5，它们的尺寸分别是输入图像的1/8、1/16和1/32，通道数分别是128、256和512。YOLOv5的Neck的剪枝方法主要是基于敏感度的剪枝，即根据通道或卷积核对网络性能的影响，删除敏感度较低的通道或卷积核，从而减少参数和计算量](https://cloud.tencent.com/developer/article/1997288)[3](https://cloud.tencent.com/developer/article/1997288)[4](https://zhuanlan.zhihu.com/p/424869462)[5](https://blog.csdn.net/qq_44878985/article/details/129287587)。
- [输出端：YOLOv5的输出端是用来生成检测结果的部分，它采用了YOLOv3](https://github.com/ultralytics/ultralytics)[8](https://github.com/ultralytics/ultralytics)[的结构，即在每个尺度的特征图上使用一个卷积层，输出一个预测张量，包含了每个网格单元的预测框的坐标、置信度和类别概率。YOLOv5的输出端的预测张量的尺寸分别是(N,3,80,80,85)、(N,3,40,40,85)和(N,3,20,20,85)，其中N是批量大小，3是每个网格单元的预测框的数量，80、40和20是每个尺度的特征图的宽度和高度，85是每个预测框的属性，包括4个坐标、1个置信度和80个类别概率。YOLOv5的输出端的剪枝方法主要是基于规则的剪枝，即根据一些预定义的规则，删除不符合规则的通道或卷积核，从而减少参数和计算量](https://zhuanlan.zhihu.com/p/424869462)[4](https://zhuanlan.zhihu.com/p/424869462)[5](https://blog.csdn.net/qq_44878985/article/details/129287587)。

找到了之前在[Releases · ultralytics/yolov5 (github.com)](https://github.com/ultralytics/yolov5/releases)发布的有用于图像分类的imagenet的yolov5预训练权重

但是有个问题是后面的网络怎么改

### 紧急想法

开始规划自己期末复习，详见另一个文档