# 12.2习得

## 综设

梳理一下整个SFM过程

当调用SFM函数时，我们仅仅需要传入是否需要进行BA优化的指定

我们首先创建一个窗口显示图像，获取相机内参并且展平为一维数组，初始化两个图像的变换矩阵

用第一个图像的相机内参和变换矩阵获得第一个图像的相机姿态估计，第二个图像的相机姿态估计初始化空

读取两个图像，下采样，计算特征点，然后计算本质矩阵，根据RANSAC算法优化，再根据掩码筛选特征点

根据本质矩阵获得相机的旋转矩阵和平移矩阵，并且返回一个用于估计相机运动的掩码，用掩码筛选出估计i相机运动的特征点，再根据相机运动的旋转矩阵和平移矩阵来更新第二个图像的变换矩阵

使用第二个图像的变换矩阵和相机内参获取第二个图像的相机姿态

我们现在得到了两张图象的姿态矩阵和特征点矩阵，三角化得到三维点云坐标，据此再次计算重投影误差

PnP算法获取更准确的相机位姿

拼接两个相机位姿矩阵

现在开始增量式重建，循环读取下一张图像，根据当前图像和下一张图像计算特征点，如果这不是第三张图像（也就不是第一次循环）需要使用之前的相机位姿矩阵和特征点进行三角化得到三维点云坐标，接着把这个齐次点云坐标转为三维坐标

获取共视特征点和相应掩码，并且根据筛选的掩码从两个特征点矩阵中提取共视点的特征点，PnP获得旋转矩阵和平移矩阵以及更新后的三维点云坐标和特征点坐标，再根据PnP获得的旋转矩阵和平移矩阵来更新变换矩阵 ，相机内参和变换矩阵计算这张图象的相机姿态矩阵

计算重投影误差，三角化

接下来就是BA的优化

最后更新参数，进入下一轮迭代做准备

循环结束后输出ply文件



---

1. **SFM 输出的稀疏点云：** 在 SFM 流程中，通过匹配特征点、恢复相机姿态和进行三角测量等步骤，生成了稀疏的三维点云。这些点通常分布在场景中的显著特征点上。
2. **密集点云生成：** 在 MVS 阶段，需要从相机视图中合成大量的视差图（Disparity Map）。这些视差图表示了在每个像素处场景的深度信息。通过从多个视角获取这些深度信息，可以生成密集的三维点云。一些 MVS 方法可能直接从图像中计算稠密点云，而不需要显式的视差图。
3. **深度图生成：** 利用相机参数和SFM的输出，可以生成深度图或视差图。这可以通过使用立体匹配算法（例如 SGM、Semi-Global Matching）或其他深度估计方法来完成。
4. **MVS 算法：** 选择适当的 MVS 算法，这可能包括 PatchMatch、COLMAP、PMVS 等。这些算法会利用深度图或视差图，并结合相机参数，生成密集的三维点云。
5. **稠密点云的三角测量（可选）：** 有时候，得到的密集点云可能需要进一步的处理，例如使用三角测量方法（Delaunay 三角剖分）来优化点云的拓扑结构。
6. **稠密点云的滤波和优化（可选）：** 对于从 MVS 得到的稠密点云，可能需要进行一些滤波和优化，以去除噪声或进一步提高点云的质量。



在 Structure from Motion（SFM）生成的稀疏点云的基础上进行稠密点云的重建通常包括以下步骤：

1. **三维点云生成：**
   在SFM中，你已经获得了稀疏的三维点云。这些点通常是通过多视图几何技术（如三角测量）从多个图像中恢复的。确保你有这些稀疏点的三维坐标。

2. **图像密集匹配：**
   利用SFM结果中的相机参数，对每一对相邻图像进行密集匹配。这可以通过光流法、立体匹配算法等实现。目标是生成每个图像的深度图或视差图。

3. **三维重建：**
   利用密集匹配的结果，结合相机参数，将深度图或视差图转换为稠密的三维点云。这可以通过反投影或三角测量等技术实现。

4. **滤波和优化：**
   对生成的稠密点云进行滤波和优化，去除噪声并提高点云的质量。滤波可以包括移动平均、高斯滤波等。

5. **表面重建（可选）：**
   如果你希望获得具有表面信息的模型，可以考虑使用表面重建算法。这些算法可以将稠密点云转换为平滑的三维网格。

6. **纹理映射（可选）：**
   如果你希望模型具有纹理信息，可以使用图像信息对三维模型进行纹理映射。这通常涉及将图像纹理映射到三维模型表面。

以下是一些示例代码，说明如何使用OpenCV进行立体匹配和三维重建：

```python
import cv2

# 读取相机参数和稀疏点云
camera_matrix = ...  # 从SFM中获取
distortion_coefficients = ...  # 从SFM中获取
sparse_points = ...  # 从SFM中获取

# 读取图像
image1 = cv2.imread('image1.jpg')
image2 = cv2.imread('image2.jpg')

# 进行立体匹配
stereo = cv2.StereoBM_create(numDisparities=16, blockSize=15)
disparity = stereo.compute(cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY), cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY))

# 通过立体匹配结果和相机参数生成稠密点云
points_3d = cv2.reprojectImageTo3D(disparity, camera_matrix)

# 进行滤波和优化（可选）
# ...

# 显示稠密点云
cv2.imshow('Dense Point Cloud', points_3d)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

请注意，以上只是一个简化的示例。具体的实现和参数设置可能取决于你的数据集、相机参数和特定任务的要求。在实际应用中，你可能需要更复杂的立体匹配和三维重建方法，以及更多的参数调整和优化。





实现从稀疏点云到稠密点云的过程通常涉及多个步骤，包括图像对齐、深度图生成和稠密点云的三维重建。以下是一个简化的Python实现的流程：

```python
import cv2
import open3d as o3d
import numpy as np

# 1. 加载稀疏点云
def load_sparse_point_cloud(ply_path):
    pcd = o3d.io.read_point_cloud(ply_path)
    return np.asarray(pcd.points), np.asarray(pcd.colors)

# 2. 图像对齐
def align_images(images):
    # 实现图像对齐的方法，可以使用特征匹配、光流等技术
    # 这里可以使用OpenCV的SIFT或者SURF等特征匹配方法
    # ...

# 3. 生成深度图
def generate_depth_map(images, aligned_images):
    # 实现深度图生成的方法，可以使用立体匹配、结构光等技术
    # 这里可以使用OpenCV的立体匹配方法或者其他深度估计方法
    # ...

# 4. 稠密点云重建
def reconstruct_dense_point_cloud(aligned_images, depth_map):
    # 实现稠密点云重建的方法，可以使用体素格或其他方法
    # 这里可以使用Open3D等库进行三维重建
    # ...

# 主流程
def main():
    # 1. 加载稀疏点云
    sparse_points, sparse_colors = load_sparse_point_cloud("sparse_point_cloud.ply")

    # 2. 图像对齐
    aligned_images = align_images(images)

    # 3. 生成深度图
    depth_map = generate_depth_map(images, aligned_images)

    # 4. 稠密点云重建
    dense_point_cloud = reconstruct_dense_point_cloud(aligned_images, depth_map)

    # 可以将生成的稠密点云保存为PLY文件
    o3d.io.write_point_cloud("dense_point_cloud.ply", o3d.geometry.PointCloud(points=o3d.utility.Vector3dVector(dense_point_cloud)))

if __name__ == "__main__":
    main()
```

上述代码仅为伪代码，实际实现会根据你选择的图像对齐、深度图生成和稠密点云重建方法而有所不同。你可能需要深入研究这些领域，查阅相关文献，并根据你的具体需求选择适当的算法和工具。在实际操作中，你可能还需要解决许多细节问题，例如相机参数的标定、图像预处理、深度图后处理等。



**我这里有一种方案：特征提取的初始化，重建面片，面片的扩展和过滤，获得多边形表面。这种方案可以实现稠密点云重建吗？**

你提到的方案涵盖了稠密点云重建的一些基本步骤。下面对你的方案中的每个步骤进行简要解释：

1. **特征提取的初始化：**
	- 这一步通常涉及从输入图像中提取特征点和特征描述子。常见的特征提取算法包括 SIFT、SURF、ORB 等。这些特征点和描述子在后续步骤中用于匹配图像。
2. **重建面片：**
	- 在这一步中，利用匹配的特征点和相机参数进行三维重建，形成初始的三维面片。这可能涉及到三角测量等技术。
3. **面片的扩展和过滤：**
	- 扩展和过滤阶段通常用于提高模型的密度和准确性。在这一步中，你可能会利用图像之间的相似性或连续性，通过迭代扩展面片以获得更多的三维点。同时，你可能会进行一些过滤，去除错误的点或噪声。
4. **获得多边形表面：**
	- 最终的步骤是将重建的点云数据转换为表示表面的多边形网格。这可以通过连接相邻点之间的三角形或四边形来实现。



**好的，在此稀疏点云重建基础上，我想进行重建面片，这里涉及到NCC得分，是这样吗？**

是的，重建面片的过程中通常涉及到 NCC（Normalized Cross-Correlation）得分或类似的相似性度量。NCC常用于图像匹配和视觉重建中，用于衡量两个图像块之间的相似程度。

在重建面片的上下文中，NCC通常用于以下步骤：

1. **特征匹配：** 利用之前提取的特征点，你可能需要在多个图像之间进行匹配。对于每对匹配的特征点，你可以定义一个局部窗口，然后计算窗口内像素值的 NCC。
2. **深度图生成：** 在匹配之后，你可以根据特征点的视差（disparity）计算深度。深度图表示了在三维空间中每个点的深度信息。
3. **面片生成：** 利用深度图，你可以将相邻像素的深度信息转化为三维点云，并连接这些点以生成初步的三维面片。
4. **扩展和过滤：** 在初步的面片生成之后，通常需要进行进一步的扩展和过滤，以改善稠密度和去除噪声。这也可能涉及到使用NCC或其他相似性度量来确保相邻面片之间的一致性。



**如果我想使用NCC得分来进行面片重建，我已经有SFM得到的稀疏点云文件以及相关结果，请你给出示例进行面片重建**

面片重建通常包括以下步骤：特征匹配、深度图生成、面片生成和过滤。在特征匹配和深度图生成阶段，NCC得分可以用于衡量图像块的相似性。以下是一个简化的示例，使用OpenCV和NumPy来演示这些步骤：

```python
import cv2
import numpy as np
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt

# 1. 读取稀疏点云
sparse_point_cloud = np.loadtxt("sparse_point_cloud.txt")  # 替换为你的稀疏点云文件路径

# 2. 读取图像
image1 = cv2.imread("image1.jpg", cv2.IMREAD_GRAYSCALE)  # 替换为你的图像路径
image2 = cv2.imread("image2.jpg", cv2.IMREAD_GRAYSCALE)

# 3. 特征匹配
orb = cv2.ORB_create()
keypoints1, descriptors1 = orb.detectAndCompute(image1, None)
keypoints2, descriptors2 = orb.detectAndCompute(image2, None)

bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
matches = bf.match(descriptors1, descriptors2)

# 4. 深度图生成
depth_map = np.zeros_like(image1, dtype=np.float32)
for match in matches:
    x1, y1 = keypoints1[match.queryIdx].pt
    x2, y2 = keypoints2[match.trainIdx].pt
    depth_map[int(y1), int(x1)] = np.abs(x2 - x1)  # 简化计算深度，实际中需要进行更复杂的计算

# 5. 面片生成（简化示例）
sparse_points_3d = np.hstack((sparse_point_cloud[:, :3], np.ones((sparse_point_cloud.shape[0], 1))))
dense_points_3d = np.dot(sparse_points_3d, np.linalg.inv(depth_map))  # 通过深度图生成三维点云

# 6. 过滤（简化示例）
# 可以添加一些过滤条件，例如去除深度为零的点等

# 7. 可视化
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(dense_points_3d[:, 0], dense_points_3d[:, 1], dense_points_3d[:, 2], c='b', marker='.')
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
plt.show()
```

请注意，这只是一个简化的示例，实际上，面片生成和过滤需要更为复杂的算法和步骤。此外，NCC的应用在这个示例中是间接的，通过ORB特征匹配得到的视差来估计深度。在实际应用中，你可能需要更复杂的特征匹配和深度估计方法，并根据你的数据和需求进行调整。



**如果我想读入稀疏点云文件格式为PLY，并且处理多张图片，请你给出示例**

在这个示例中，我将使用Python中的Open3D库来读取PLY格式的稀疏点云文件，并通过多张图像进行面片重建。请确保你已经安装了Open3D库，可以使用 `pip install open3d` 进行安装。

```python
import open3d as o3d
import cv2
import numpy as np
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt

# 1. 读取稀疏点云（PLY文件）
sparse_ply_path = "sparse_point_cloud.ply"  # 替换为你的PLY文件路径
sparse_point_cloud = o3d.io.read_point_cloud(sparse_ply_path)
sparse_points = np.asarray(sparse_point_cloud.points)
sparse_colors = np.asarray(sparse_point_cloud.colors)

# 2. 处理多张图像
image_paths = ["image1.jpg", "image2.jpg"]  # 替换为你的图像路径列表
images = [cv2.imread(path, cv2.IMREAD_GRAYSCALE) for path in image_paths]

# 3. 特征匹配和深度图生成
orb = cv2.ORB_create()

# 使用第一张图像的特征点和描述子作为参考
keypoints_ref, descriptors_ref = orb.detectAndCompute(images[0], None)

# 遍历其他图像，进行特征匹配和深度图生成
depth_maps = []
for i in range(1, len(images)):
    keypoints, descriptors = orb.detectAndCompute(images[i], None)

    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    matches = bf.match(descriptors_ref, descriptors)

    depth_map = np.zeros_like(images[0], dtype=np.float32)
    for match in matches:
        x_ref, y_ref = keypoints_ref[match.queryIdx].pt
        x, y = keypoints[match.trainIdx].pt
        depth_map[int(y_ref), int(x_ref)] = np.abs(x - x_ref)

    depth_maps.append(depth_map)

# 4. 面片生成和过滤
dense_points = []

# 使用第一张图像的稀疏点云作为初始点
sparse_points_3d = np.hstack((sparse_points, np.ones((sparse_points.shape[0], 1))))

# 遍历深度图，生成稠密点云
for i, depth_map in enumerate(depth_maps):
    dense_points_3d = np.dot(sparse_points_3d, np.linalg.inv(depth_map))
    dense_points.extend(dense_points_3d)

dense_points = np.array(dense_points)

# 5. 过滤（简化示例，可以添加更复杂的过滤条件）
dense_points = dense_points[dense_points[:, 2] > 0]  # 去除深度为零的点

# 6. 可视化
fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(dense_points[:, 0], dense_points[:, 1], dense_points[:, 2], c='b', marker='.')
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
plt.show()
```

请注意，这个示例仍然是一个简化版本，实际中你可能需要更多的处理步骤和参数调整。同时，对于更复杂的场景和更多的图像，可能需要使用更先进的特征匹配和深度估计算法。



**我现在通过SFM获得了稀疏点云文件(PLY)以及相关结果，我想在此基础上实现稠密点云重建，这个过程可能涉及到重建面片（使用最优化NCC得分），面片扩展和过滤，深度图生成，获得多边形表面，请你给出代码**

以下是一个简单的Python代码示例，用于从稀疏点云文件中重建稠密点云，并生成多边形表面：

```python
import numpy as np
#pyvista 用于处理三维数据和可视化
import pyvista as pv

# Load sparse point cloud from PLY file
ply = pv.read('sparse_point_cloud.ply')

# Reconstruct dense point cloud using SFM
# (replace this with your own SFM code)
dense_points = np.random.rand(ply.n_points, 3)

# Compute normal vectors for each point using PyVista
normals = ply.point_normals

# Compute neighbor information for each point using PyVista
kdtree = pv.KDTree(ply)
_, idx, _ = kdtree.radius_neighbors(radius=0.1, return_distance=True)

# Reconstruct polygons using normal vectors and neighbor information
polygons = []
for i in range(ply.n_points):
    neighbors = idx[i]
    normal = normals[i]
    polygons.append(pv.PolyData(ply.points[neighbors], faces=pv.PolyData(ply.points[neighbors]).triangulate().faces))

# Extend polygons to fill in gaps and remove small areas
extended_polygons = []
for polygon in polygons:
    extended_polygon = polygon.triangulate().decimate(0.1)
    extended_polygons.append(extended_polygon)

# Filter out polygons with low surface area
filtered_polygons = []
for polygon in extended_polygons:
    if polygon.area > 0.01:
        filtered_polygons.append(polygon)

# Generate depth map from dense point cloud and polygons
depth_map = pv.PolyData(dense_points, faces=pv.PolyData(dense_points).triangulate().faces).point_arrays['depth']

# Extract polygons from depth map
polygon_points = []
for polygon in filtered_polygons:
    polygon_points.append(dense_points[polygon.points])

# Save polygons to file
np.save('polygon_points.npy', polygon_points)
```

这个代码示例使用了PyVista库来进行点云处理和多边形重建。首先，它从PLY文件中加载稀疏点云，并使用SFM算法重建稠密点云。然后，它使用PyVista库计算每个点的法向量，并使用KD树查找每个点的近邻点。接下来，它使用法向量和近邻点信息重建多边形，并使用PyVista库进行多边形扩展和过滤。最后，它使用稠密点云和多边形生成深度图，并从深度图中提取多边形点。最后，它将多边形点保存到文件中。

---

SFM类的初始化就是指定传入的文件夹

而文件夹类就是加载相机参数和图像列表