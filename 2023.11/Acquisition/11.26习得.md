# 11.26习得

## 总结

大概梳理了一下这周

## 科研

### predict.py

总的来说就是实现预测功能，操作细节如下：

跑本程序需要输入一定的命令行参数，包括权重文件、图像路径、设备等等，传入main函数后，函数开始执行图推断：首先是预处理，包括设置设备、结果目录等等，先使用一张虚拟图像进行模型的热身，然后读取传入的数据（图像），预处理之后输入图像推理，对输出结果概率排序，选取前五个类别的索引记录，将结果记录于日志中，最后是输出时间以及显示

### train.py

本文件和predict相似，但明显多了几个烦扰项：分布式训练和多线程。

首先获取命令行参数，检查当前是否为主进程——是的话就是正常情况然后打印命令行参数，检查Git状态和所需的依赖项即可，设置训练设备，如果处于分布式训练模式就进行相关参数的检查和初始化，接下来设置保存结果的路径，开始训练train()

train封装了大部分内容

首先设置随机数种子，从命令行参数中提取常用选项，，设置各种目录，保存命令行参数（*.yaml）,创建日志记录，根据分布式选项让主线程加载数据，获取数据集的类别数，获取训练数据加载器和测试数据加载器，接下来是获取模型，我们需要根据命令参数的是否指定文件来确定，然后是调整分类器的类别数，下面是对模型从检测模型到分类模型到适配，包括“修改分类数，设置可以更新，修改模型参数，移动设备”等，我们还需要输出模型结构和参数数量等信息记录，现在我们开始设置一系列训练所需：优化器、学习率、学习率调度器、EMA，开始训练，后面基本就是正常的，不同的是我们用到amp和scaler，同时记录信息，最后保存各种文件

### 查看参数文件*.pt

#### 直接打印的结构：

Conv  Conv

C3 : Conv Conv Conv  Bottleneck( Conv Conv )

Conv

C3 : Conv Conv Conv  Bottleneck( Conv Conv )  Bottleneck( Conv Conv )

Conv

C3 : Conv Conv Conv  Bottleneck( Conv Conv )  Bottleneck( Conv Conv ) Bottleneck( Conv Conv )

Conv

C3 : Conv Conv Conv  Bottleneck( Conv Conv )

Classify : Conv pool drop liner

有问题，不能据此改网络名字，必须看到pt文件里面的层的名称

#### 最后具体层的名字还是print了出来，见桌面文件

### 梳理一下load_model函数

——我们据此来改网络架构

因为resnet有多种版本，所以我们存在多个配置，这需要首先说明

加载模型函数首先是需要传入了两个参数：模型和初始预训练参数字典

加载模型先进行一些准备工作：函数本身需要传入模型的指定和初始状态的参数字典，我们先根据传入的模型获取当前的状态字典（和初始预训练参数文件字典一样），命令行参数指定了模型，据此我们选择残差网络的具体模型的配置，就是残差块的数量排列，初始化一个列表all_honey_conv_weight存储所有卷积权重的名称，为空，设置一个BN层不同部分，比如权重 偏置，再设置前缀  后缀  计数器

因为所有残差网络的第一层都是一个卷积，所以我们直接在all_honey_conv_weight添加名称，获取初始权重和当下权重，进而获取第一层的初始卷积核数和当下卷积核数

开始重点工作：

如果第一层的两种卷积核数目两个不相等，我们根据之前设定的前缀  后缀  计数器直接获取rank，根据rank得到保留卷积核的索引（通过原始卷积核数量与当前卷积核数量差值去欸的确定保留数量，再从排序中选取此数量的即可），再根据保留卷积核索引将对应的原始权重和BN层的参数copy到当前权重和BN层

如果卷积核数目两个相等（对resnet来说就是相等的），简单替换bn部分（分布式训练所需的）就行，其他就不需要选择和替换，直接copy即可

第一层的最后把初始状态的['bn1' + '.num_batches_tracked']复制到当前状态的state_dict[name_base + 'bn1' + '.num_batches_tracked']

现在我们处理残差网络的关键——多个残差块，在遍历每个模块中每个残差块中每个卷积层和bn层中，把每个卷积层和BN层的名字处理后添加到all_honey_conv_weight列表中，然后获取原始卷积核数量和当下卷积核数量

判定如果当下卷积核数量和原始卷积核数量是否相等，不相等就加载rank，这里需要多一个进一步的判定：last_select_index之前是否已经选择过卷积核，如果没选择过，需要遍历last_select_index来copy卷积层，BN的copy正常，如果选择过，正常copy

如果当下卷积核数量和原始卷积核数量相等，并且之前选择过卷积核，遍历原始卷积核数目时遍历last_select_index来copy，BN正常

最后一种情况：如果当下卷积核数量和原始卷积核数量相等，并且之前没选择过卷积核，直接copy

当上一次进行了剪枝后才有下次的 last_select_index

最后加载模型的权重参数，并进行替换：遍历所有模块，获取名称，去除模块中前缀module.，检查当前模块，卷积层就构建权重名称，如果名称不在all_honey_conv_weight，说明不需要替换，直接把原始权重copy即可，当前模块是全连接层，就直接copy原始权重

别忘模型需要加载剪枝过的参数

### 梳理一下main函数

更应该梳理的是main函数，因为load_model只是main中的一个步骤

首先用正则表达式解析命令行参数指定的压缩率，然后是加载指定的模型，设定损失函数，数据加载器准备，计算初始状态下的参数量和计算量，根据指定的检查点文件获取适配好名称的参数字典，参数字典加载到模型中，如果明确是从检查点文件继续训练，就加载检查点文件，替换参数字典中的参数名称得到新参数字典，加载到模型中，如果不是从检查点文件继续训练，加载预训练模型load_model，现在直接调用train和val开始训练和验证，最后保存

#### 为什么会出现两次替换参数字典中键名，不是重复了吗？

注意第一次是当在测试模式下，我们加载检查点文件，替换“module”为“”后加载到模型中，后面情况下再进行从检查点继续训练的一次替换和加载，当分布式训练时替换是“module“+删除”module“的原键名，否则正常删除“module”即可，不从检查点继续训练就直接加载预训练参数权重到模型中，然后load_model修改。根本还是：加载检查点文件，获取参数字典，替换键名，新参数字典加载到模型中。

### load_model函数还有一个明显的问题——不理解 last_select_index 意义

---

### 梳理原本网络架构——加入compressing_rate

——我们仍然以resnet为例 

#### 待做！

#### 大致分析了yolo.py

梳理到这里其实已经比较清晰了，load_main函数起码可以做了

我发现自己做完预训练情况下的load_model 函数后可能还要修改原本的resume部分

至于本来的网络架构，还是根据yolo.py文件来做